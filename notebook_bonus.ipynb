{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "wj94dDIHUitH",
      "metadata": {
        "id": "wj94dDIHUitH"
      },
      "source": [
        "\n",
        "Reproducibility Project Notebook Bonus for CS598 DL4H in Spring 2023<br />\n",
        "\n",
        "Charles Stolz - cstolz2@illinois.edu<br />\n",
        "Sean Enright - seanre2@illinois.edu<br />\n",
        "\n",
        "\n",
        "Group ID: 77<br />\n",
        "Paper ID: 155<br />\n",
        "\n",
        "Code: https://github.com/rylandtikes/cs598-project<br />\n",
        "Presentation: https://youtu.be/LFLJMnoj0mg <br />\n",
        "\n",
        "This notebook reproduces the research in:\n",
        "\n",
        "[Variationally Regularized Graph-based Representation Learning for Electronic Health Records](https://arxiv.org/abs/1912.03761)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ZcN1sLvxMXgq",
      "metadata": {
        "id": "ZcN1sLvxMXgq"
      },
      "source": [
        "## Table of Contents:\n",
        "* [Purpose](#Purpose)\n",
        "* [Summary of Findings](#Summary-of-Findings)\n",
        "* [Key Results](#Key-Results)\n",
        "* [MIMIC-III Data](#MIMIC-III-Data)\n",
        "* [eICU Data](#eICU-Data)\n",
        "* [Experiments](#Experiments)\n",
        "* [References](#References)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "YfxIGiiiIDbF",
      "metadata": {
        "id": "YfxIGiiiIDbF"
      },
      "source": [
        "# Summary of Findings\n",
        "\n",
        "## Result 1: Encoder-decoder Mortality Prediction with MIMIC-III\n",
        "\n",
        "After making minor hyperparameter adjustments to address the memory-intensive nature of this task, we were able to reproduce the authors' results for MIMIC-III well. Performance of the Enc-dec model exceeded the published value by 1.8%, which also supports the claim that the Enc-dec model performs better than the earlier classical and graph-based methods described above. \n",
        "\n",
        "## Result 2: Encoder-decoder Readmission Prediction with eICU\n",
        "\n",
        "Reproducing the eICU data proved more challenging. Our training data shows both inconsistency in the performance of the Enc-dec model on readmission prediction, and overall lower performance than described in the paper. We have included a representative result in our analysis. Using the hyperparameters reported in the paper, performance of the Enc-dec model was lower than the authors' result by 7.5%. Furthermore, its performance is worse than all of the competing methods described by the authors. By modifying the weight of the L2 norm penalty term, performance improved significantly, but was still 3.0% lower than the reported value. The performance of this model is superior to all three classical methods, but is inferior to the Transformer and GCT models, contrary to Claim 2. \n",
        "\n",
        "\n",
        "## Result 3: Variational Regularization Improves Performance Over Encoder-decoder\n",
        "\n",
        "The performance of the VGNN model supports Claim 3, i.e., that the model improves over the Enc-dec network, but this result only holds for MIMIC-III data. The performance on eICU data has proven to consistently lower than that of Enc-dec, despite extensive hyperparameter experiments, contrary to the claim. The performance of the VGNN matches the authors' result within 1.3% for the MIMIC-III prediction task after modifying batch size to address memory concerns.\n",
        "However, the representative performance of VGNN on the eICU prediction task falls short of the published result by 13.4% using the hyperparameters listed in the paper, a difference similar to the result seen in the Enc-dec network on this dataset. Our optimizations to the hyperparameters improved model performance, but still fell behind the published value by 10.0%.\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "j-sotuFHPpU_",
      "metadata": {
        "id": "j-sotuFHPpU_"
      },
      "source": [
        "# MIMIC-III Data\n",
        "![MIMIC-III Tables](./images/mimic-iii_data.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "35jfz3S9RkbT",
      "metadata": {
        "id": "35jfz3S9RkbT"
      },
      "source": [
        "# eICU Data\n",
        "![eICU Tables](./images/eicu_data.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eLoiVKztTO7M",
      "metadata": {
        "id": "eLoiVKztTO7M"
      },
      "source": [
        "# Results for Mortality Prediction with MIMIC-III Dataset\n",
        "![MIMIC-III Results](./images/mimic-iii_results.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fe2b1c93",
      "metadata": {},
      "source": [
        "# Results for Readmission Prediction with eICU Dataset\n",
        "![eICU Results](./images/eicu_results.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Aqa5nQMGzCe",
      "metadata": {
        "id": "0Aqa5nQMGzCe"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Clone the project Git Repo if needed. Preprocessed eICU and MIMIC-III data will be needed for training\n",
        "Scripts to create the datasets available under /data of below repo\n",
        "\"\"\"\n",
        "\n",
        "#!git clone https://github.com/rylandtikes/cs598-project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29-EusdbIljG",
      "metadata": {
        "id": "29-EusdbIljG"
      },
      "outputs": [],
      "source": [
        "# Verify files downloaded\n",
        "!ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "pwBDv6pgROb0",
      "metadata": {
        "id": "pwBDv6pgROb0"
      },
      "source": [
        "# Experiments\n",
        "Execute the below code to reproduce the experiments"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "UXd_UMhYQ815",
      "metadata": {
        "id": "UXd_UMhYQ815"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nnb7aVxfIwyi",
      "metadata": {
        "id": "nnb7aVxfIwyi"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "%pip install numpy\n",
        "%pip install pandas\n",
        "%pip install protobuf\n",
        "%pip install scikit_learn\n",
        "%pip install scipy\n",
        "%pip install tensorflow\n",
        "%pip install torch\n",
        "%pip install tqdm\n",
        "%pip install pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b360cc",
      "metadata": {
        "id": "81b360cc"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import os\n",
        "import logging\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from torch.utils.data import Dataset\n",
        "import copy\n",
        "import csv\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import shutil"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "gZ2l2amIMBpm",
      "metadata": {
        "id": "gZ2l2amIMBpm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fce3921",
      "metadata": {
        "id": "2fce3921"
      },
      "outputs": [],
      "source": [
        "# Verify Nvidia Drivers setup (optional uncomment if desired)\n",
        "# !nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "u3gb7OoUGx2t",
      "metadata": {
        "id": "u3gb7OoUGx2t"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7638a4a1",
      "metadata": {
        "id": "7638a4a1"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39e49462",
      "metadata": {
        "id": "39e49462"
      },
      "outputs": [],
      "source": [
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9396e7d",
      "metadata": {
        "id": "b9396e7d"
      },
      "outputs": [],
      "source": [
        "# Verify available memory on GPU\n",
        "print(torch.cuda.memory_summary(device=0, abbreviated=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b01a2b7",
      "metadata": {
        "id": "4b01a2b7"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "\n",
        "def clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "\n",
        "def clone_params(param, N):\n",
        "    return nn.ParameterList([copy.deepcopy(param) for _ in range(N)])\n",
        "\n",
        "\n",
        "class Regularized(torch.nn.Module):\n",
        "    \"\"\"Wrapper of PyTorch module to allow regularization calculations to be performed on gradient \n",
        "       for more efficient computation.\n",
        "\n",
        "       Hook-based approach adapted from regularization module in\n",
        "       https://github.com/szymonmaszke/torchlayers\n",
        "    \"\"\"\n",
        "    def __init__(self, module, norm_type='l2', weight_decay=0):\n",
        "        super().__init__()\n",
        "        self.module = module\n",
        "        self.weight_decay = weight_decay\n",
        "        if norm_type not in ('l2', 'l1'):\n",
        "            raise ValueError('Unsupported norm type')\n",
        "        self.regularize = self.l1 if norm_type=='l1' else self.l2\n",
        "        # Backward hook is registered on the specified module\n",
        "        self.hook = self.module.register_full_backward_hook(self._weight_decay_hook)\n",
        "\n",
        "    def _weight_decay_hook(self, *_):\n",
        "        \"\"\"Applies regularization to each parameter in module at gradient level.\n",
        "        \"\"\"\n",
        "        for param in self.module.parameters():\n",
        "            param.grad = self.regularize(param)\n",
        "\n",
        "    def l1(self, parameter):\n",
        "        \"\"\"Calculates L1 norm for a given module parameter.\n",
        "\n",
        "        Args:\n",
        "            parameter (torch.nn.parameter.Parameter): module parameter\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: updated gradient after regularization\n",
        "        \"\"\"\n",
        "        return self.weight_decay * torch.sign(parameter.data)\n",
        "    \n",
        "    def l2(self, parameter):\n",
        "        \"\"\"Calculates L2 norm for a given module parameter.\n",
        "\n",
        "        Args:\n",
        "            parameter (torch.nn.parameter.Parameter): module parameter\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: updated gradient after regularization\n",
        "        \"\"\"\n",
        "        return self.weight_decay * parameter.data\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        \"\"\"Forward pass returns inner module's own forward method.\n",
        "\n",
        "        Returns:\n",
        "            torch.nn.Module: inner module\n",
        "        \"\"\"\n",
        "        return self.module(*args, **kwargs)\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "\n",
        "class GraphLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, hidden_features, out_features, num_of_nodes,\n",
        "                 num_of_heads, dropout, alpha, concat=True):\n",
        "        super(GraphLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.hidden_features = hidden_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "        self.num_of_nodes = num_of_nodes\n",
        "        self.num_of_heads = num_of_heads\n",
        "        # Attention\n",
        "        # Linear layers for multi-head attention\n",
        "        self.W = clones(\n",
        "            nn.Linear(in_features, hidden_features),\n",
        "            num_of_heads\n",
        "            )\n",
        "        # Parameters for multi-head attention\n",
        "        self.a = clone_params(\n",
        "            nn.Parameter(torch.rand(size=(1, 2 * hidden_features)), requires_grad=True),\n",
        "            num_of_heads\n",
        "            )\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "        # FFN applied after attention\n",
        "        self.linear = nn.Linear(hidden_features, out_features)\n",
        "        if concat:\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.Dropout(dropout),\n",
        "                LayerNorm(hidden_features),\n",
        "                nn.ELU()\n",
        "            )\n",
        "        else:\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.Dropout(dropout),\n",
        "                LayerNorm(hidden_features),\n",
        "                nn.ReLU(),\n",
        "                self.linear\n",
        "            ) \n",
        "\n",
        "    def initialize(self, init_method=nn.init.xavier_normal_):\n",
        "        \"\"\"Set initial weights in model.\n",
        "        \"\"\"\n",
        "        for i in range(len(self.W)):\n",
        "            init_method(self.W[i].weight.data)\n",
        "        for i in range(len(self.a)):\n",
        "            init_method(self.a[i].data)\n",
        "        if not self.concat:\n",
        "            init_method(self.linear.weight.data)\n",
        "\n",
        "    def attention(self, linear, a, data, edges):\n",
        "        \"\"\"Updates representation by graph propagation with self-attention.\n",
        "\n",
        "            Uses 'Method 2': the inner product of a learnable vector and the concatenation of two\n",
        "            relevant representations.\n",
        "\n",
        "        Args:\n",
        "            linear (torch.Module): linear layer\n",
        "            a (torch.Parameter): parameters of attention\n",
        "            data (torch.Tensor): representation of EHR codes,\n",
        "                                 of shape (self.num_of_nodes, embedding dim)\n",
        "            edge (torch.Tensor): edge connectivity vector for observed codes, of shape (2, v_obs^2)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: updated representation of EHR codes after attenention from graph\n",
        "        \"\"\"\n",
        "        data = linear(data).unsqueeze(0)\n",
        "        # h: self.num_of_nodes x out\n",
        "        h = torch.cat(\n",
        "            (data[:, edges[0, :], :],\n",
        "             data[:, edges[1, :], :]), dim=0)\n",
        "        data = data.squeeze(0)\n",
        "        # edge_h: 2*D x E\n",
        "        edge_h = torch.cat(\n",
        "            (h[0, :, :],\n",
        "             h[1, :, :]), dim=1).transpose(0, 1)\n",
        "        # d_h: dimensionality of embedding dimension\n",
        "        d_h = np.sqrt(self.hidden_features * self.num_of_heads)\n",
        "        # edge_e: E\n",
        "        edge_e = torch.exp(self.leakyrelu(a.mm(edge_h).squeeze()) / d_h)\n",
        "        edge_e = torch.sparse_coo_tensor(\n",
        "            edges.to(device),\n",
        "            edge_e.to(device),\n",
        "            torch.Size([self.num_of_nodes, self.num_of_nodes])\n",
        "            )\n",
        "        e_rowsum = torch.sparse.mm(edge_e, torch.ones(size=(self.num_of_nodes, 1)).to(device))\n",
        "        # e_rowsum: N x 1\n",
        "        row_check = (e_rowsum == 0)\n",
        "        e_rowsum[row_check] = 1\n",
        "        zero_idx = row_check.nonzero()[:, 0]\n",
        "        edge_e = edge_e.add(torch.sparse.FloatTensor(\n",
        "                               zero_idx.repeat(2, 1),\n",
        "                               torch.ones(len(zero_idx)).to(device),\n",
        "                               torch.Size([self.num_of_nodes, self.num_of_nodes])\n",
        "                               ))\n",
        "        # edge_e: E\n",
        "        h_prime = torch.sparse.mm(edge_e, data)\n",
        "        # h_prime: N x out\n",
        "        h_prime.div_(e_rowsum)\n",
        "        return h_prime\n",
        "\n",
        "    def forward(self, edges, data=None):\n",
        "        \"\"\"Uses fully connected graph to update representation of EHR codes via self-attention.\n",
        "\n",
        "        Args:\n",
        "            edge (torch.Tensor): edge connectivity vector for observed codes, of shape (2, v_obs^2)\n",
        "            data (torch.Tensor): representation of EHR codes,\n",
        "                                 of shape (self.num_of_nodes, embedding dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: updated representation of EHR codes\n",
        "        \"\"\"\n",
        "        # If using multi-head attention (self.num_of_heads > 1), compute attention coeffs multiple\n",
        "        # times. If is input layer (self.concat), aggregate coeffs by concatenation.\n",
        "        attn_list = []\n",
        "        for w, a in zip(self.W, self.a):\n",
        "            attn_out = self.attention(w, a, data, edges)\n",
        "            attn_list.append(attn_out)\n",
        "        if self.concat:\n",
        "            h_prime = torch.cat(attn_list, dim=1)\n",
        "        else:\n",
        "            h_prime = torch.stack(attn_list, dim=0).mean(dim=0)\n",
        "        # FFN\n",
        "        return self.ffn(h_prime)\n",
        "\n",
        "\n",
        "class VariationalGNN(nn.Module):\n",
        "    \"\"\"Graph-based neural network. Encoder-decoder (Enc-dec) or variationally regulated (VGNN).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, num_of_nodes, n_heads, n_layers,\n",
        "                 dropout, alpha, variational=True, excluded_features=0, mask_prob=0):\n",
        "        super(VariationalGNN, self).__init__()\n",
        "        self.variational = variational\n",
        "        self.num_of_nodes = num_of_nodes + 1 - excluded_features\n",
        "        self.out_features = out_features\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.excluded_features = excluded_features\n",
        "        self.mask_prob = mask_prob\n",
        "\n",
        "        # Encoder\n",
        "        self.embed = nn.Embedding(self.num_of_nodes, in_features, padding_idx=0)\n",
        "        self.in_att = clones(\n",
        "            GraphLayer(in_features, in_features, in_features, self.num_of_nodes,\n",
        "                       n_heads, dropout, alpha, concat=True),\n",
        "            n_layers)\n",
        "        \n",
        "        # Variational regularization\n",
        "        self.parameterize = nn.Linear(out_features, out_features * 2)\n",
        "\n",
        "        # Decoder\n",
        "        self.out_att = GraphLayer(in_features, in_features, out_features, self.num_of_nodes,\n",
        "                                  n_heads, dropout, alpha, concat=False)\n",
        "        decoder_output_size = out_features\n",
        "        if excluded_features > 0:\n",
        "            decoder_output_size = out_features + out_features // 2\n",
        "            self.features_ffn = nn.Sequential(\n",
        "                nn.Linear(excluded_features, out_features // 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "                )\n",
        "        self.out_layer = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(decoder_output_size, out_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(out_features, 1)\n",
        "            )\n",
        "        \n",
        "        # Initialize encoder graph layers\n",
        "        for i in range(n_layers):\n",
        "            self.in_att[i].initialize()\n",
        "        self.out_att.initialize()\n",
        "\n",
        "    @staticmethod\n",
        "    def make_fc_graph_edges(nodes):\n",
        "        \"\"\"Creates a graph connectivity vector in COO format for a complete undirected graph from\n",
        "           a given set of nodes.\n",
        "\n",
        "        Args:\n",
        "            nodes (torch.Tensor): nodes of shape (n)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: graph connectivity vector in COO format\n",
        "        \"\"\"\n",
        "        n = nodes.size()[1]\n",
        "        source = nodes.repeat(1, n) # non-zero nodes in order, repeated n times\n",
        "        dest = nodes.repeat(n, 1).transpose(0, 1).contiguous().view((1, n ** 2))\n",
        "        return torch.cat((source, dest), dim=0)\n",
        "\n",
        "    def data_to_edges(self, codes):\n",
        "        \"\"\"Creates input and output graph connectivity vectors in COO format from a set of nodes.\n",
        "           Both graphs are complete and undirected. The output graph consists of the input graph\n",
        "           and one additional node for prediction.\n",
        "\n",
        "           While training, to improve the robustness of the model dealing with sparse data,\n",
        "           observed codes will be removed with variable probability.\n",
        "\n",
        "        Args:\n",
        "            codes (torch.Tensor): tensor of EHR codes for a single patient\n",
        "\n",
        "        Returns:\n",
        "            (torch.Tensor, torch.Tensor): input and output graph connectivity in COO format\n",
        "        \"\"\"\n",
        "        n = codes.size()[0]\n",
        "        observed = codes.nonzero() # observed EHR codes, of shape (num_nonzero, 1)\n",
        "        if observed.size()[0] == 0:\n",
        "            return torch.LongTensor([[0], [0]]), torch.LongTensor([[n + 1], [n + 1]])\n",
        "        if self.training:\n",
        "            # Exclude observed codes with 0.05 probability\n",
        "            mask = torch.rand(observed.size()[0])\n",
        "            mask = mask > self.mask_prob\n",
        "            observed = observed[mask]\n",
        "            if observed.size()[0] == 0:\n",
        "                return torch.LongTensor([[0], [0]]), torch.LongTensor([[n + 1], [n + 1]])\n",
        "        # Input edges\n",
        "        # Nodes, of shape (1, n), incremented by 1\n",
        "        observed = observed.transpose(0, 1) + 1\n",
        "        input_edges = self.make_fc_graph_edges(observed)\n",
        "        # Output edges\n",
        "        # Adds a node at the end with value n + 1. Will act as prediction node.\n",
        "        observed = torch.cat((observed, torch.LongTensor([[n + 1]]).to(device)), dim=1)\n",
        "        output_edges = self.make_fc_graph_edges(observed)\n",
        "\n",
        "        return input_edges.to(device), output_edges.to(device)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Sample latent variables from distribution to become input to decoder. Used in\n",
        "           variational regularization.\n",
        "\n",
        "        Args:\n",
        "            mu (torch.Tensor): mean\n",
        "            logvar (torch.Tensor): variance\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: samples of latent distribution\n",
        "        \"\"\"\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = std.data.new(std.size()).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def encoder_decoder(self, codes):\n",
        "        \"\"\"Passes batch through the Encoder-decoder network\n",
        "\n",
        "            First, embeddings of medical concepts are made.\n",
        "            Medical embeddings are processed by the encoder to form the graph representation. In\n",
        "            each graph layer, the graph representation is updated via self-attention.\n",
        "            If variational, a latent layer is added between the encoder and decoder to regularize\n",
        "            the graph representation.\n",
        "            The output of the encoder is then passed through the decoder, which consists of one\n",
        "            layer and self-attention. The output is the representation of the predictive node.\n",
        "\n",
        "        Args:\n",
        "            codes (torch.Tensor): EHR codes for one patient of shape (num codes)\n",
        "\n",
        "        Returns:\n",
        "            (torch.Tensor, torch.Tensor): inference from decoder output of shape (embedding_dim)\n",
        "                                          and KL divergence\n",
        "        \"\"\"\n",
        "        # Embedding of medical concepts\n",
        "        # h_prime: (num_of_nodes, embedding_dim)\n",
        "        h_prime = self.embed(torch.arange(self.num_of_nodes).long().to(device))\n",
        "        # Encoder\n",
        "        # input_edges: input graph edge connection matrix of fully-connected nodes after masking\n",
        "        # output_edges: output graph edge connection matrix of input nodes and one additional node\n",
        "        input_edges, output_edges = self.data_to_edges(codes)\n",
        "        for attn in self.in_att:\n",
        "            h_prime = attn(input_edges, h_prime)\n",
        "        # If variational regularization is used, add linear layer and sample distribution\n",
        "        if self.variational:\n",
        "            h_prime = self.parameterize(h_prime).view(-1, 2, self.out_features)\n",
        "            h_prime = self.dropout(h_prime)\n",
        "            mu = h_prime[:, 0, :]\n",
        "            # The variance is parameterized as an exponential to ensure non-negativity\n",
        "            logvar = h_prime[:, 1, :]\n",
        "            h_prime = self.reparameterize(mu, logvar)\n",
        "            mu = mu[codes, :]\n",
        "            logvar = logvar[codes, :]\n",
        "        # Decoder\n",
        "        # The last row of h_prime is the representation of an additional node for prediction\n",
        "        h_prime = self.out_att(output_edges, h_prime)\n",
        "        out = h_prime[-1]\n",
        "        # If applying variational regularization, KL divergence is needed\n",
        "        if self.variational:\n",
        "            kld = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2)) / mu.size()[0]\n",
        "        else:\n",
        "            kld = torch.tensor(0.0).to(device)\n",
        "        return out, kld\n",
        "\n",
        "    def forward(self, batch):\n",
        "        \"\"\"Forward pass of VGNN or Enc-dec network.\n",
        "\n",
        "           Steps:\n",
        "           Pass nodes for each patient in batch through Encoder-decoder network, giving the\n",
        "           prediction task embedding from the decoder output and the KL divergence.\n",
        "           Determine logits (unnormalized predictions) concatenating the decoder output for all\n",
        "           patients and passing through ReLU and a FFN (self.out_layer).\n",
        "           Sum KL divergence for all patients.\n",
        "\n",
        "           If any features are excluded from the graph, they are separated, and pass through\n",
        "           self.features_ffn and then joined with the encoder-decoder output, which acts on the\n",
        "           non-excluded features.\n",
        "\n",
        "        Args:\n",
        "            batch (torch.Tensor): batch of shape (batch size, num nodes)\n",
        "\n",
        "        Returns:\n",
        "            (torch.Tensor, torch.Tensor): logits and KL divergence\n",
        "        \"\"\"\n",
        "        kld_batch = []\n",
        "        included_batch = []\n",
        "        if self.excluded_features == 0:\n",
        "            for i in range(batch.size()[0]):\n",
        "                out, kld = self.encoder_decoder(batch[i, :])\n",
        "                included_batch.append(out)\n",
        "                kld_batch.append(kld)\n",
        "                out_batch = torch.stack(included_batch)\n",
        "        else:\n",
        "            excluded_batch = []\n",
        "            for i in range(batch.size()[0]):\n",
        "                out, kld = self.encoder_decoder(batch[i, self.excluded_features:])\n",
        "                included_batch.append(out)\n",
        "                kld_batch.append(kld)\n",
        "                excluded_nodes = torch.FloatTensor([batch[i, :self.excluded_features]]).to(device)\n",
        "                excluded_batch.append(self.features_ffn(excluded_nodes))\n",
        "            out_batch = torch.cat((torch.stack(excluded_batch), torch.stack(included_batch)),\n",
        "                                  dim=1)\n",
        "        logits = self.out_layer(out_batch)\n",
        "        kld_sum = torch.sum(torch.stack(kld_batch))\n",
        "        return logits, kld_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d4920e",
      "metadata": {
        "id": "d3d4920e"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "\n",
        "def train(data, model, optim, criterion, kl_scale, max_clip_norm=5):\n",
        "    \"\"\"Trains model for one batch and reports loss.\n",
        "\n",
        "    Args:\n",
        "        data (torch.Tensor): batch of shape (batch size, num nodes)\n",
        "        model (torch.nn.Module): model being used to train\n",
        "        optim (torch.optim): optimizer to hold state and update parameters based on gradients\n",
        "        criterion: loss function\n",
        "        kl_scale (float): weight of KL divergence term\n",
        "        max_clip_norm (int, optional): maximum norm of gradient before it is clipped. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        (float, float, float): loss, KL divergence and BCE loss after model training pass\n",
        "    \"\"\"\n",
        "    #model.train()\n",
        "    # The last code is the label\n",
        "    input = data[:, :-1].to(device)\n",
        "    label = data[:, -1].float().to(device)\n",
        "    # Training\n",
        "    model.train()\n",
        "    optim.zero_grad()\n",
        "    logits, kld = model(input)\n",
        "    # Loss considers binary cross-entropy and weighted KL divergence\n",
        "    logits = logits.squeeze(-1)\n",
        "    kld = kld.sum()\n",
        "    bce = criterion(logits, label)\n",
        "    loss = bce + kl_scale * kld\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_clip_norm)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    return loss.item(), kld.item(), bce.item()\n",
        "\n",
        "\n",
        "def evaluate(model, data_iter, length):\n",
        "    model.eval()\n",
        "    y_pred = np.zeros(length)\n",
        "    y_true = np.zeros(length)\n",
        "    y_prob = np.zeros(length)\n",
        "    pointer = 0\n",
        "    for data in data_iter:\n",
        "        input = data[:, :-1].to(device)\n",
        "        label = data[:, -1]\n",
        "        batch_size = len(label)\n",
        "        probability, _ = model(input)\n",
        "        probability = torch.sigmoid(probability.squeeze(-1).detach())\n",
        "        predicted = probability > 0.5\n",
        "        y_true[pointer: pointer + batch_size] = label.numpy()\n",
        "        y_pred[pointer: pointer + batch_size] = predicted.cpu().numpy()\n",
        "        y_prob[pointer: pointer + batch_size] = probability.cpu().numpy()\n",
        "        pointer += batch_size\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
        "    return auc(recall, precision), (y_pred, y_prob, y_true)\n",
        "\n",
        "\n",
        "class EHRData(Dataset):\n",
        "    def __init__(self, data, cla):\n",
        "        self.data = data\n",
        "        self.cla = cla\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cla)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.cla[idx]\n",
        "\n",
        "\n",
        "def collate_fn(data):\n",
        "    # padding\n",
        "    data_list = []\n",
        "    for datum in data:\n",
        "        data_list.append(np.hstack((datum[0].toarray().ravel(), datum[1])))\n",
        "    return torch.from_numpy(np.array(data_list)).long()        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54467c93",
      "metadata": {
        "id": "54467c93"
      },
      "outputs": [],
      "source": [
        "# Change values here if using notebook configuration\n",
        "\n",
        "reg_options = [\"l2\", \"l1\", \"none\"]\n",
        "\n",
        "config_dict = {\n",
        "    \"batch_size\": 32,\n",
        "    \"data_path\": \"./eicu-data/\",\n",
        "    \"dropout\": 0.4,\n",
        "    \"embedding_size\": 128,\n",
        "    \"eval_freq\": 1,\n",
        "    \"excluded_features\": 0,\n",
        "    \"leaky_relu_alpha\": 0.1,\n",
        "    \"lr\": 0.0001,\n",
        "    \"manual_seed\": 0,\n",
        "    \"mask_prob\": 0.1,\n",
        "    \"num_of_epochs\": 1,\n",
        "    \"num_of_heads\": 1,\n",
        "    \"num_of_layers\": 2,\n",
        "    \"overwrite_save\": False,\n",
        "    \"reg_method\": \"l1\",\n",
        "    \"reg_weight\": 1e-2,\n",
        "    \"result_path\": \"./Enc-Dec_L1/\",\n",
        "    \"save_model\": True,\n",
        "    \"test\": True,\n",
        "    \"upsample_factor\": 2,\n",
        "    \"var\": False,\n",
        "    \"var_scale\": 1.0,\n",
        "    \"weight_decay\": 1e-2,\n",
        "}\n",
        "\n",
        "\n",
        "# Change to True to use a local configuration file instead of notebook\n",
        "read_configuration_from_file = True\n",
        "\n",
        "local_config_file = \"./train_mimic_none.yaml\"\n",
        "if read_configuration_from_file:\n",
        "    with open(local_config_file, mode=\"rt\", encoding=\"utf-8\") as file_handle:\n",
        "        config_dict = yaml.safe_load(file_handle)\n",
        "\n",
        "\n",
        "# The values below should not be changed.\n",
        "################################################################################\n",
        "batch_size = config_dict[\"batch_size\"]\n",
        "# input path of processed dataset\n",
        "data_path = config_dict[\"data_path\"]\n",
        "dropout = config_dict[\"dropout\"]\n",
        "embedding_size = config_dict[\"embedding_size\"]\n",
        "eval_freq = config_dict[\"eval_freq\"]\n",
        "excluded_features = config_dict[\"excluded_features\"]\n",
        "leaky_relu_alpha = config_dict[\"leaky_relu_alpha\"]\n",
        "# learning rate\n",
        "lr = config_dict[\"lr\"]\n",
        "manual_seed = config_dict[\"manual_seed\"]\n",
        "mask_prob = config_dict[\"mask_prob\"]\n",
        "num_of_epochs = config_dict[\"num_of_epochs\"]\n",
        "# number of attention heads\n",
        "num_of_heads = config_dict[\"num_of_heads\"]\n",
        "# number of graph layers\n",
        "num_of_layers = config_dict[\"num_of_layers\"]\n",
        "overwrite_save = config_dict[\"overwrite_save\"]\n",
        "# regularization\n",
        "reg_method = config_dict[\"reg_method\"]\n",
        "reg_weight = float(config_dict[\"reg_weight\"])\n",
        "# output path of model checkpoints\n",
        "result_path = config_dict[\"result_path\"]\n",
        "save_model = config_dict[\"save_model\"]\n",
        "test = config_dict[\"test\"]\n",
        "upsample_factor = config_dict[\"upsample_factor\"]\n",
        "var = config_dict[\"var\"]\n",
        "var_scale = config_dict[\"var_scale\"]\n",
        "weight_decay = float(config_dict[\"weight_decay\"])\n",
        "\n",
        "in_features = embedding_size\n",
        "out_features = embedding_size\n",
        "################################################################################\n",
        "\n",
        "\n",
        "gradient_max_norm = 5  # clip gradient to prevent exploding gradient\n",
        "# Name of the configuration file written to result path\n",
        "config_file = \"config.yaml\"\n",
        "\n",
        "if manual_seed >= 0:\n",
        "    torch.manual_seed(manual_seed)\n",
        "\n",
        "# Load data and upsample training data\n",
        "train_x, train_y = None, None\n",
        "if test:\n",
        "    train_x, train_y = pickle.load(open(data_path + \"test_csr.pkl\", \"rb\"))\n",
        "else:\n",
        "    train_x, train_y = pickle.load(open(data_path + \"train_csr.pkl\", \"rb\"))\n",
        "    train_upsampling = np.concatenate(\n",
        "        (\n",
        "            np.arange(len(train_y)),\n",
        "            np.repeat(np.where(train_y == 1)[0], upsample_factor - 1),\n",
        "        )\n",
        "    )\n",
        "    train_x = train_x[train_upsampling]\n",
        "    train_y = train_y[train_upsampling]\n",
        "val_x, val_y = pickle.load(open(data_path + \"validation_csr.pkl\", \"rb\"))\n",
        "\n",
        "# Configure logging\n",
        "model_name = f\"VGNN_{var_scale}\" if var else \"Enc-dec\"\n",
        "reg_name = \"\" if reg_method == \"none\" else f\"reg_{reg_method}_{reg_weight}\"\n",
        "result_folder = (\n",
        "    f\"{model_name}-{reg_name}-lr_{lr}-dropout_{dropout}-\"\n",
        "    f\"embed_{in_features}-batch_{batch_size}\"\n",
        ")\n",
        "if test:\n",
        "    result_folder += \"-TEST\"\n",
        "result_root = Path(result_path) / result_folder\n",
        "result_root.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Write config file\n",
        "with open(result_root / config_file, mode=\"wt\", encoding=\"utf-8\") as cf:\n",
        "    yaml.dump(config_dict, cf)\n",
        "\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "logging.basicConfig(\n",
        "    filename=result_root / \"train.log\",\n",
        "    format=\"%(asctime)s %(message)s\",\n",
        "    level=logging.INFO,\n",
        ")\n",
        "dataset_name = \"test\" if test else \"training\"\n",
        "logging.info(f\"Begin training with {dataset_name} dataset...\")\n",
        "# csv\n",
        "csv_fields = [\"Epoch\", \"AUPRC\", \"Loss\", \"BCE\", \"KLD\"]\n",
        "csv_log = open(result_root / \"train.csv\", \"wt\", encoding=\"utf-8\", buffering=1)\n",
        "csv_writer = csv.DictWriter(csv_log, delimiter=\",\", fieldnames=csv_fields)\n",
        "csv_writer.writeheader()\n",
        "\n",
        "# initialize models\n",
        "num_of_nodes = train_x.shape[1] + 1\n",
        "device_ids = range(torch.cuda.device_count())\n",
        "\n",
        "# eICU has 1 feature on previous readmission that we didn't include in the graph\n",
        "model = VariationalGNN(\n",
        "    in_features,\n",
        "    out_features,\n",
        "    num_of_nodes,\n",
        "    num_of_heads,\n",
        "    num_of_layers - 1,\n",
        "    dropout=dropout,\n",
        "    alpha=leaky_relu_alpha,\n",
        "    variational=var,\n",
        "    excluded_features=excluded_features,\n",
        "    mask_prob=mask_prob,\n",
        ").to(device)\n",
        "if reg_method != \"none\":\n",
        "    model = Regularized(model, reg_method, reg_weight)\n",
        "model = nn.DataParallel(model, device_ids=device_ids)\n",
        "val_loader = DataLoader(\n",
        "    dataset=EHRData(val_x, val_y),\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=torch.cuda.device_count(),\n",
        "    shuffle=False,\n",
        ")\n",
        "optimizer = optim.AdamW(\n",
        "    [p for p in model.parameters() if p.requires_grad], lr=lr, weight_decay=weight_decay\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Train models\n",
        "for epoch in range(num_of_epochs):\n",
        "    train_loader = DataLoader(\n",
        "        dataset=EHRData(train_x, train_y),\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=torch.cuda.device_count(),\n",
        "        shuffle=True,\n",
        "    )\n",
        "    # BCE Loss is weighted by positive-negative ratio\n",
        "    counter = Counter(train_y)\n",
        "    ratio = counter[True] / counter[False]\n",
        "    pos_weight = torch.ones(1).float().to(device) * ratio\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction=\"sum\", pos_weight=pos_weight)\n",
        "\n",
        "    # Configure logging within epoch\n",
        "    print(f'Epoch: {epoch + 1}, Learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "    num_batches = len(train_loader)\n",
        "    last_batch = num_batches - 1\n",
        "    update_interval = max(round(num_batches / 20.0, 0), 1)\n",
        "\n",
        "    # Iterate through batches within epoch\n",
        "    model.train()\n",
        "    total_loss = np.zeros(3)\n",
        "    t = tqdm(iter(train_loader), leave=False, total=last_batch, unit=\"batch\")\n",
        "    for idx, batch_data in enumerate(t):\n",
        "        # Train model on batch\n",
        "        loss, kld, bce = train(\n",
        "            batch_data, model, optimizer, criterion, var_scale, gradient_max_norm\n",
        "        )\n",
        "        total_loss += np.array([loss, bce, kld])\n",
        "        if idx > 0:\n",
        "            curr_loss = total_loss[0] / idx\n",
        "            curr_bce = total_loss[1] / idx\n",
        "            curr_kld = total_loss[2] / idx\n",
        "        # Report training progress within batch via tqdm\n",
        "        if (idx % update_interval == 0 or idx == last_batch) and idx > 0:\n",
        "            progress = (\n",
        "                f\"Loss: {curr_loss:.4f}, BCE: {curr_bce:.4f}, KLD: {curr_kld:.4f}\"\n",
        "            )\n",
        "            t.set_description(progress)\n",
        "            t.refresh()\n",
        "        # Save model's state dictionary to file\n",
        "        if save_model and idx == last_batch and not test:\n",
        "            param_file = (\n",
        "                \"parameter\"\n",
        "                if overwrite_save\n",
        "                else f\"parameter-epoch_{epoch}-batch_{idx}\"\n",
        "            )\n",
        "            torch.save(model.state_dict(), result_root / param_file)\n",
        "        # Evaluate and log training\n",
        "        if idx == last_batch and (epoch + 1) % eval_freq == 0:\n",
        "            val_auprc, _ = evaluate(model, val_loader, len(val_y))\n",
        "            prog = {\n",
        "                \"Epoch\": epoch + 1,\n",
        "                \"AUPRC\": f\"{val_auprc:.4f}\",\n",
        "                \"Loss\": f\"{curr_loss:.4f}\",\n",
        "                \"BCE\": f\"{curr_bce:.4f}\",\n",
        "                \"KLD\": f\"{curr_kld:.4f}\",\n",
        "            }\n",
        "            csv_writer.writerow(prog)\n",
        "            eval_log = (\n",
        "                f'Epoch: {prog[\"Epoch\"]}, AUPRC: {prog[\"AUPRC\"]}, '\n",
        "                f'Loss: {prog[\"Loss\"]}, BCE: {prog[\"BCE\"]}, KLD: {prog[\"KLD\"]}'\n",
        "            )\n",
        "            logging.info(eval_log)\n",
        "            print(f\"AUPRC: {val_auprc:.4f}\")\n",
        "    scheduler.step()\n",
        "csv_log.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pnPG7N-XerSl",
      "metadata": {
        "id": "pnPG7N-XerSl"
      },
      "outputs": [],
      "source": [
        "# Compress the results and copy to Google drive if desired\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nkYBTivTmDOt",
      "metadata": {
        "id": "nkYBTivTmDOt"
      },
      "outputs": [],
      "source": [
        "!ls {result_path}/{result_folder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pyMONzdvnjWI",
      "metadata": {
        "id": "pyMONzdvnjWI"
      },
      "outputs": [],
      "source": [
        "!cat {result_path}/{result_folder}/config.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RoKAdSB5oe-e",
      "metadata": {
        "id": "RoKAdSB5oe-e"
      },
      "outputs": [],
      "source": [
        "!cat {result_path}/{result_folder}/train.csv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "G7r3g8OnC5l3",
      "metadata": {
        "id": "G7r3g8OnC5l3"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "Edward Choi, Zhen Xu, Yujia Li, Michael W. Dusen-\n",
        "  berry, Gerardo Flores, Yuan Xue, and Andrew M. Dai.\n",
        "  2019. Graph convolutional transformer: Learning\n",
        "  the graphical structure of electronic health records.\n",
        "  CoRR, abs/1906.04716.\n",
        "\n",
        "Alistair E.W. Johnson, Tom J. Pollard, Lu Shen, Li-\n",
        "  wei H. Lehman, Mengling Feng, Mohammad Ghas-\n",
        "  semi, Benjamin Moody, Peter Szolovits, Leo An-\n",
        "  thony Celi, Roger G. Mark, and et al. 2016. Mimic-\n",
        "  iii, a freely accessible critical care database. Scien-\n",
        "  tific Data, 3(1).\n",
        "\n",
        "Tom J. Pollard, Alistair E. Johnson, Jesse D. Raffa,\n",
        "  Leo A. Celi, Roger G. Mark, and Omar Badawi.\n",
        "  2018. The eicu collaborative research database, a\n",
        "  freely available multi-center database for critical care\n",
        "  research. Scientific Data, 5(1).\n",
        "\n",
        "Charles Stolz and Sean Enright. 2023. Cs598:\n",
        "  Deep learning for healthcare reproducibility\n",
        "  project. https://github.com/rylandtikes/\n",
        "  cs598-project.\n",
        "\n",
        "Weicheng Zhu and Narges Razavian. 2021. Variation-\n",
        "  ally regularized graph-based representation learning\n",
        "  for electronic health records. In Proceedings of\n",
        "  the Conference on Health, Inference, and Learning,\n",
        "  CHIL ’21, page 1–13, New York, NY, USA. Associa-\n",
        "  tion for Computing Machinery.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
